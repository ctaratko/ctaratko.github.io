[
  {
    "objectID": "danl200-hw5-Taratko-Christopher.html#word",
    "href": "danl200-hw5-Taratko-Christopher.html#word",
    "title": "danl200-hw5-Taratko-Christopher.qmd",
    "section": "Word",
    "text": "Word\n\n2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "The goal intended of the research and analysis of the stocks performed was to help people understand what certain stocks would classify as, whether it be a good investment overall, something preferable for the short/long run, what the volatility of a stock is, and other performance functions that would help the reader grasp what to look for when investing."
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\n\nCode\nsummary(StocksUpdated2)\n\n\n   Company              Date             Close/Last         Volume         \n Length:25160       Length:25160       Min.   :  1.62   Min.   :1.144e+06  \n Class :character   Class :character   1st Qu.: 36.57   1st Qu.:1.200e+07  \n Mode  :character   Mode  :character   Median : 65.68   Median :2.672e+07  \n                                       Mean   :102.46   Mean   :5.132e+07  \n                                       3rd Qu.:134.24   3rd Qu.:6.857e+07  \n                                       Max.   :691.69   Max.   :1.065e+09  \n      Open             High             Low        \n Min.   :  1.62   Min.   :  1.69   Min.   :  1.61  \n 1st Qu.: 36.51   1st Qu.: 36.89   1st Qu.: 36.13  \n Median : 65.65   Median : 66.48   Median : 64.92  \n Mean   :102.43   Mean   :103.83   Mean   :101.01  \n 3rd Qu.:134.32   3rd Qu.:136.23   3rd Qu.:132.66  \n Max.   :692.35   Max.   :700.99   Max.   :686.09"
  },
  {
    "objectID": "project.html#jack-katz---research-question-1-which-stocks-have-the-most-historical-volatility.",
    "href": "project.html#jack-katz---research-question-1-which-stocks-have-the-most-historical-volatility.",
    "title": "DANL Project",
    "section": "2.2 Jack Katz - Research Question 1: Which stocks have the most historical volatility.",
    "text": "2.2 Jack Katz - Research Question 1: Which stocks have the most historical volatility.\n\n2.2.1 Creating new variables for analysis, Separating by month day and year will make it easier to group and filter observations by year.\n#Historical volatility of each company for each year.  A simple measure of historical volatility is calculated by finding the standard deviation  of the close prices over a time series. In this case we found the standard deviation for  each stock for each year and then showed this data on ggplot.\n\nHistorical_Volatility &lt;- Volatility_analysis %&gt;% \n  group_by(Company, Year) %&gt;% \n  summarise(Volatility = sd(`Close/Last`))\n\nVolatility &lt;- ggplot(Historical_Volatility,\n       mapping = aes(x = as.numeric(Year),\n                     y = Volatility\n                     )) +\n  geom_point(color = \"blue\") +\n  geom_line(color = \"green\") +\n  facet_wrap( . ~Company) +\n  ggtitle(\"Stock Price Volatility from 2013-2023\", subtitle = \"In dollars\") +\n  labs(x = \"Year\") +\n  theme_economist_white()\n\nVolatility + scale_x_continuous(breaks = scales::breaks_width(2))"
  },
  {
    "objectID": "Analytics200Review.html",
    "href": "Analytics200Review.html",
    "title": "Lab Exercises - DANL 200",
    "section": "",
    "text": "Data Analytics Lab Review (In Class Exercises)\nThese Lab Exercises consist of if statements, for loops, while loops, and repeat statements\n\n\n\n\n1 Lab 7\n\n# IN-CLASS EXERCISE\n#   Create an if-else statement example in R that assigns a hypothetical starting salary based on different education levels. We’ll consider three levels of education: High School, Bachelor’s Degree, and Master’s Degree.\n\n#In this example:\n\n#   If the education level is “High School”, the starting salary is set to $30,000.\n#   If the education level is “Bachelor’s Degree”, the starting salary is set to $50,000.\n#   If the education level is “Master’s Degree”, the starting salary is set to $70,000.\n#   For any other education level not explicitly listed, the default starting salary is set to $40,000.\n\n# At the beginning, insert education level is “Bachelor’s Degree”, and Initialize the starting salary at 0. At the end use print() to show the result.\n\nEducation &lt;- \"Bachelor's Degree\"\nStarting_Salary &lt;- 0\nif (Education == \"High School\") {\n  Starting_Salary &lt;- 30000\n} else if (Education == \"Bachelor's Degree\") {\n  Starting_Salary &lt;- 50000\n} else if (Education == \"Master's Degree\") {\n  Starting_Salary &lt;- 70000\n} else {\n  Starting_Salary &lt;- 40000\n}\nprint(paste(\"This person has a \",Education,\" and their starting salary will be $\",Starting_Salary,sep = ''))\n\n[1] \"This person has a Bachelor's Degree and their starting salary will be $50000\"\n\n\n\n\n2 Lab 8\n\n#     In-Class Exercise: Adjusting Discount Rates Based on Purchase Amount\n# Exercise Description: Based on the previous example, now introduce an additional \n# condition: for premium members, if their purchase amount exceeds $200, they get \n# a 15% discount instead of 10%. all the rest are same, including non exceeds $200 \n# will get 10% and Non-premium members still do not receive any discount.\n\n\n# Purchase amounts and membership status\npurchase_amounts &lt;- c(100, 150, 200, 250, 300)\nis_premium_member &lt;- c(TRUE, FALSE, TRUE, FALSE, TRUE)\n\n# Initialize a vector to hold the final amounts, the initial value doesn't matter, eventually they will updated. But the length is important, it gives us the vector of results.\nfinal_amounts &lt;- numeric(length(purchase_amounts))\n\n# Use a for loop with if-else statement to apply discounts\nfor (i in 1:length(purchase_amounts)) {\n  if (is_premium_member[i] && purchase_amounts[i] &gt; 200) {\n    final_amounts[i] &lt;- purchase_amounts[i] * .85  # Applied 15% discount\n  } else if (is_premium_member[i]) {\n    final_amounts[i] &lt;- purchase_amounts[i] * 0.9  # Apply 10% discount\n  } else {\n    final_amounts[i] &lt;- purchase_amounts[i]  # No discount\n  } # My formatting (Works)\n}\n\n# for (i in 1:length(purchase_amounts)) \n#   if (is_premium_member[i]) {\n#     if (is_premium_member[i] && purchase_amounts[i] &gt; 200) {\n#       final_amounts[i] &lt;- purchase_amounts[i] * 0.85  # Applied 15% discount \n#     } else {\n#     final_amounts[i] &lt;- purchase_amounts[i] * 0.9  # Apply 10% discount\n#   }\n#     } else {\n#     final_amounts[i] &lt;- purchase_amounts[i]  # No discount\n#   } # Li Lu's Formatting (Cleaner Formatting, nested if statements)\n\nprint(final_amounts)\n\n[1]  90 150 180 250 255\n\n\n\n\n3 Lab 9\n\n# In-Class Exercise: Inventory for a popular book\n# Exercise Description: You own a small bookstore, and you keep track of the inventory for a popular book. Initially, you have 50 books in stock. Throughout the day, customers buy them, and you record each sale. Your policy is to order 30 more books whenever your stock drops below 10 to ensure you always have enough books to meet demand. The simulation stops after ordering more books once, for simplicity.\n\n\n# Initial Setup\nInitial_Stock &lt;- 50\nOrderThreshold &lt;- 10\nOrderQ &lt;- 30\nCurrentStock &lt;- Initial_Stock\nrepeat {\n  while (CurrentStock &gt; OrderThreshold) {\n  Q_Book_Sold &lt;- sample(1:5,1)\n  CurrentStock &lt;- CurrentStock - Q_Book_Sold\n  print(paste(\"The initial Stock of\",Initial_Stock,\"has been reduced to:\",CurrentStock))\n  } \n  if (CurrentStock &lt;= OrderThreshold) {\n  print(paste(\"Stock originally was at:\", CurrentStock))\n  CurrentStock &lt;- CurrentStock + OrderQ\n  print(paste(\"The updated Stock is now at:\", CurrentStock))\n  break\n  } \n}\n\n[1] \"The initial Stock of 50 has been reduced to: 46\"\n[1] \"The initial Stock of 50 has been reduced to: 41\"\n[1] \"The initial Stock of 50 has been reduced to: 37\"\n[1] \"The initial Stock of 50 has been reduced to: 32\"\n[1] \"The initial Stock of 50 has been reduced to: 30\"\n[1] \"The initial Stock of 50 has been reduced to: 29\"\n[1] \"The initial Stock of 50 has been reduced to: 25\"\n[1] \"The initial Stock of 50 has been reduced to: 21\"\n[1] \"The initial Stock of 50 has been reduced to: 18\"\n[1] \"The initial Stock of 50 has been reduced to: 14\"\n[1] \"The initial Stock of 50 has been reduced to: 10\"\n[1] \"Stock originally was at: 10\"\n[1] \"The updated Stock is now at: 40\"\n\n\n\n\n4 Another Class Exercise\n\nConsumerPoints &lt;- 85\nwhile (ConsumerPoints &lt; 140) {\n  if (ConsumerPoints &lt; 100) {\n    ConsumerPoints &lt;- ConsumerPoints + 5\n    print(ConsumerPoints)\n  } else if (ConsumerPoints &gt;= 100) {\n    ConsumerPoints &lt;- ConsumerPoints + 5\n    print(paste(\"You have\", ConsumerPoints, \"Points!\",\"\"))\n    readline(\"Would you like to Convert your Points to Cash: [Y/N] \")\n    break\n  }\n}\n\n[1] 90\n[1] 95\n[1] 100\n[1] \"You have 105 Points! \"\nWould you like to Convert your Points to Cash: [Y/N] \n\n\n\n\n[1] \"This Website has been fixed\""
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Christopher Taratko",
    "section": "",
    "text": "About Me\n\nI have majors in\nAccounting & Economics\n,with a Minor in\nData Analytics\nat SUNY Geneseo. When not working on college assignments, I enjoy sailing, snowboarding, zip-lining, rock climbing and gaming. Other interesting facts about me is that I have a Level 1 Sailing Certification, I race sailboats competitively through the summer and winter seasons, and my hopes for my college education is to bring a balance within Data Analytics and Accounting. I see both of these majors as essential to each other, especially now that AI will cause job uncertainty in programmable positions and is being developed to predict markets.\n\nEducation\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026 Minor in Data Analytics\nExperience\nDaidone Income Tax LLC - Mentorship\nLinkedIn Learning - Excel Tutorial\nLinkedIn Learning - Intermediate Excel\nLinkedIn Learning - Excel - Financial Functions in Depth\nLinkedIn Learning - Managing and Analyzing Data in Excel"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let’s analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI’ll begin with these analyses and create visualizations to help us understand the data better. Let’s start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let’s calculate the average quantity purchased and average spending per purchase. For this, we’ll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we’ll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we’ll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let’s move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI’ll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let’s look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let’s proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe’ll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we’ll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let’s calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there’s a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let’s move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe’ll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We’ll do this for each brand to see which brands are most affected by promotions.\nLet’s begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn’t. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "NVDY Planner",
    "section": "",
    "text": "NVDY Dividend Reinvestment Code\n\nThe reinvestment planner for the ticker, NVDY, is based off of the stock ticker for Nvidia (NVDA), where ProShares performs options trading on behalf of the shareholders in order to generate profits for said shareholders and the company through the distribution of Stock prices and dividends payments which can vary greatly, but have performed well in the past year, allowing shareholders to receive 1.5x shares through just monthly dividend reinvestment in this past year.\nThe strategies used for these option trades can vary immensely, but would look as if they contain a self\n\nCode-Block:"
  },
  {
    "objectID": "IndexRenderDeploy.html",
    "href": "IndexRenderDeploy.html",
    "title": "Christopher Taratko",
    "section": "",
    "text": "About Me\n\nI have majors in\nAccounting & Economics\n,with a Minor in\nData Analytics\nat SUNY Geneseo. When not working on college assignments, I enjoy sailing, snowboarding, zip-lining, rock climbing and gaming. Other interesting facts about me is that I have a Level 1 Sailing Certification, I race sailboats competitively through the summer and winter seasons, and my hopes for my college education is to bring a balance within Data Analytics and Accounting. I see both of these majors as essential to each other, especially now that AI will cause job uncertainty in programmable positions and is being developed to predict markets.\n\nEducation\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026 Minor in Data Analytics\nExperience\nDaidone Income Tax LLC - Mentorship\nLinkedIn Learning - Excel Tutorial\nLinkedIn Learning - Intermediate Excel\nLinkedIn Learning - Excel - Financial Functions in Depth\nLinkedIn Learning - Managing and Analyzing Data in Excel\n\n\n\n\n# #| echo: false\n# const DATA_ENTRY_SHEET_NAME = \"1BT-M6uJ5OdLBnojAMorrafl7VW6GBaSbZMJJD3h-_08\"; # 1BT-M6uJ5OdLBnojAMorrafl7VW6GBaSbZMJJD3h-_08\n# var sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(DATA_ENTRY_SHEET_NAME);\n# \n# const doPost = (request = {}) =&gt; {\n#   const { postData: { contents, type } = {} } = request;\n#   if (!contents) {\n#     console.error('No postData contents found');\n#     return ContentService.createTextOutput('No postData contents found').setMimeType(ContentService.MimeType.TEXT);\n#   }\n#   var data = parseFormData(contents);\n#   if (data) {\n#     appendToGoogleSheet(data);\n#     return ContentService.createTextOutput(JSON.stringify(data)).setMimeType(ContentService.MimeType.JSON);\n#   } else {\n#     return ContentService.createTextOutput('Error parsing form data').setMimeType(ContentService.MimeType.TEXT);\n#   }\n# };\n# \n# function parseFormData(postData) {\n#   if (typeof postData !== 'string') {\n#     console.error('postData is not a string:', postData);\n#     return null;\n#   }\n#   var data = {};\n#   var parameters = postData.split('&');\n#   for (var i = 0; i &lt; parameters.length; i++) {\n#     var [key, value] = parameters[i].split('=');\n#     data[key] = decodeURIComponent(value.replace(/\\+/g, ' '));\n#   }\n#   return data;\n# }\n# \n# function appendToGoogleSheet(data) {\n#   var headers = sheet.getRange(1, 1, 1, sheet.getLastColumn()).getValues()[0];\n#   var rowData = headers.map(headerFld =&gt; data[headerFld] || \"\");\n#   sheet.appendRow(rowData);\n# }\n# \n#"
  },
  {
    "objectID": "posts/Stock Code/index.html",
    "href": "posts/Stock Code/index.html",
    "title": "Stocks",
    "section": "",
    "text": "This is a post with executable code.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nStockPost &lt;- read_csv(\"/Users/christophertaratko/ProjectsList/Data Analytics/Personal Website/ctaratko.github.io/StocksUpdated2.csv\")\n\nRows: 25160 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Company, Date\ndbl (5): Close/Last, Volume, Open, High, Low\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nview(StockPost)"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "quarto-template.html",
    "href": "quarto-template.html",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "",
    "text": "oj &lt;- read_csv('https://bcdanl.github.io/data/dominick_oj.csv')\nnvars &lt;- format(round(ncol(oj), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(oj), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 4; the number of observations is 28,947.\nRoses are red\nviolets are blue."
  },
  {
    "objectID": "quarto-template.html#data-summary",
    "href": "quarto-template.html#data-summary",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "quarto-template.html#data-visualization",
    "href": "quarto-template.html#data-visualization",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\noj %&gt;% \n  ggplot(aes(x = log(sales), \n             y = log(price),\n             color = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = lm, se = F) +\n  facet_wrap(.~ad) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "quarto-template.html#data-transformation",
    "href": "quarto-template.html#data-transformation",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.3 Data Transformation",
    "text": "2.3 Data Transformation\n\nob_sum1 &lt;- oj %&gt;% \n  group_by(brand, ad) %&gt;% \n  summarise(sales_tot = sum(sales, na.rm = T),\n            price_mean = round(mean(price, na.rm = T), 2))"
  },
  {
    "objectID": "quarto-template.html#analysis",
    "href": "quarto-template.html#analysis",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "quarto-template.html#quotes",
    "href": "quarto-template.html#quotes",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n“The truth is rarely pure and never simple.”\n— Oscar Wilde"
  },
  {
    "objectID": "quarto-template.html#inserting-figures",
    "href": "quarto-template.html#inserting-figures",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: DANL Tiger"
  },
  {
    "objectID": "quarto-template.html#inserting-a-html-page",
    "href": "quarto-template.html#inserting-a-html-page",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "DANL210_Project.html#background",
    "href": "DANL210_Project.html#background",
    "title": "Data Analytics – [Project Name]",
    "section": "- Background",
    "text": "- Background\n\nProvide context for the research questions, explaining why they are significant, relevant, or interesting"
  },
  {
    "objectID": "DANL210_Project.html#statement-of-the-problem",
    "href": "DANL210_Project.html#statement-of-the-problem",
    "title": "Data Analytics – [Project Name]",
    "section": "- Statement of the Problem",
    "text": "- Statement of the Problem\n\n\n\n\n\n\nImportant\n\n\n\nThis is a callout, it’ll help define items on my page that might be important, or other such key features. You can find this at PositCo’s Cheatsheet page\n\n\n\nClearly articulate the specific problem or issue the project will address."
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNVDY Planner\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nChristopher Taratko\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nStocks\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nChristopher Taratko\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "PortfolioDevelopment.html",
    "href": "PortfolioDevelopment.html",
    "title": "Portfolio Development",
    "section": "",
    "text": "NVDY Reinvestment Data Planner\nThe Dividend Reinvestment Calculator is an array of charted values based on a given amount of NVDY in terms of USD Valuation or number of shares.  \nThe given valuation will be more or less volatile, as the provided date comes from the date of dividend payouts, rather than all daily valuations. This is not meant to be a secured planner, but just a general visualization of how money invested into this can grow and by what growth the stock has already seen\nContributions\nSite Owner: Christopher Taratko\nContributors: Professor Li Lu & Professor Byeong-Hak Choe\n\n\n\n\n\n\n\nFunctionality of The Reinvestment Calculator:\nThe Calculator / Graph is designed to be a User Input based service (Which will occur in the future) that will be able to calculate the monthly and overall returns.\n\nThe current calculator does not have an input function due to the lack of JavaScript knowledge on my end, but it will be temporarily resolved with a ShinyApp variable slider (Ex. '$50,$100,$500,$1000,$5000... $100000' or in terms of # of shares)."
  },
  {
    "objectID": "project.html#creating-new-variables-for-analysis-separating-by-month-day-and-year-will-make-it-easier-to-group-and-filter-observations-by-year.",
    "href": "project.html#creating-new-variables-for-analysis-separating-by-month-day-and-year-will-make-it-easier-to-group-and-filter-observations-by-year.",
    "title": "DANL Project",
    "section": "3.1 Creating new variables for analysis, Separating by month day and year will make it easier to group and filter observations by year.",
    "text": "3.1 Creating new variables for analysis, Separating by month day and year will make it easier to group and filter observations by year."
  },
  {
    "objectID": "project.html#historical-volatility-of-each-company-for-each-year.",
    "href": "project.html#historical-volatility-of-each-company-for-each-year.",
    "title": "DANL Project",
    "section": "3.1 Historical volatility of each company for each year.",
    "text": "3.1 Historical volatility of each company for each year.\nA simple measure of historical volatility is calculated by finding the standard deviation of the close prices over a time series. In this case we found the standard deviation for each stock for each year and then showed this data on ggplot.\n\n\nCode\nHistorical_Volatility &lt;- Volatility_analysis %&gt;% \n  group_by(Company, Year) %&gt;% \n  summarise(Volatility = sd(`Close/Last`))\n\nVolatility &lt;- ggplot(Historical_Volatility,\n       mapping = aes(x = as.numeric(Year),\n                     y = Volatility\n                     )) +\n  geom_point(color = \"blue\") +\n  geom_line(color = \"green\") +\n  facet_wrap( . ~Company) +\n  ggtitle(\"Stock Price Volatility from 2013-2023\", subtitle = \"In dollars\") +\n  labs(x = \"Year\") +\n  theme_economist_white()\n\nVolatility + scale_x_continuous(breaks = scales::breaks_width(2))"
  }
]