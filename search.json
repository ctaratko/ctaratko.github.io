[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Stocks",
    "section": "",
    "text": "This is a post with executable code.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nStockPost &lt;- read_csv(\"/Users/christophertaratko/ProjectsList/Data Analytics/Personal Website/ctaratko.github.io/StocksUpdated2.csv\")\n\nRows: 25160 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Company, Date\ndbl (5): Close/Last, Volume, Open, High, Low\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nview(StockPost)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "NVDY Planner",
    "section": "",
    "text": "NVDY Dividend Reinvestment Code\n\nCreating a secured future for myself and others is a plan I wish to enact. With that being said, I’ve begun to learn how to code various ways to get financial data from useful resources like finance.yahoo, Robinhood, and tools such as Quantmod.\n\nCode-Block:"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let’s analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI’ll begin with these analyses and create visualizations to help us understand the data better. Let’s start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let’s calculate the average quantity purchased and average spending per purchase. For this, we’ll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we’ll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we’ll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let’s move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI’ll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let’s look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let’s proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe’ll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we’ll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let’s calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there’s a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let’s move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe’ll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We’ll do this for each brand to see which brands are most affected by promotions.\nLet’s begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn’t. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Christopher Taratko",
    "section": "",
    "text": "About Me\n\nI have majors in\nAccounting & Economics\n,with a Minor in\nData Analytics\nat SUNY Geneseo. When not working on college assignments, I enjoy sailing, snowboarding, zip-lining, rock climbing and gaming. Other interesting facts about me is that I have a Level 1 Sailing Certification, I race sailboats competitively through the summer and winter seasons, and my hopes for my college education is to bring a balance within Data Analytics and Accounting. I see both of these majors as essential to each other, especially now that AI will cause job uncertainty in programmable positions and is being developed to predict markets.\n\nEducation\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026 Minor in Data Analytics\nExperience\nDaidone Income Tax LLC - Mentorship\nLinkedIn Learning - Excel Tutorial\nLinkedIn Learning - Intermediate Excel\nLinkedIn Learning - Excel - Financial Functions in Depth\nLinkedIn Learning - Managing and Analyzing Data in Excel"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Christopher Taratko",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026  Minor in Data Analytics"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Christopher Taratko",
    "section": "Experience",
    "text": "Experience\nToo much for anyone to handle… (N/A)"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nNVDY Planner\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nChristopher Taratko\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nStocks\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nChristopher Taratko\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "The goal intended of the research and analysis of the stocks performed was to help people understand what certain stocks would classify as, whether it be a good investment overall, something preferable for the short/long run, what the volatility of a stock is, and other performance functions that would help the reader grasp what to look for when investing."
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nsummary(StocksUpdated2)\n\n   Company              Date             Close/Last         Volume         \n Length:25160       Length:25160       Min.   :  1.62   Min.   :1.144e+06  \n Class :character   Class :character   1st Qu.: 36.57   1st Qu.:1.200e+07  \n Mode  :character   Mode  :character   Median : 65.68   Median :2.672e+07  \n                                       Mean   :102.46   Mean   :5.132e+07  \n                                       3rd Qu.:134.24   3rd Qu.:6.857e+07  \n                                       Max.   :691.69   Max.   :1.065e+09  \n      Open             High             Low        \n Min.   :  1.62   Min.   :  1.69   Min.   :  1.61  \n 1st Qu.: 36.51   1st Qu.: 36.89   1st Qu.: 36.13  \n Median : 65.65   Median : 66.48   Median : 64.92  \n Mean   :102.43   Mean   :103.83   Mean   :101.01  \n 3rd Qu.:134.32   3rd Qu.:136.23   3rd Qu.:132.66  \n Max.   :692.35   Max.   :700.99   Max.   :686.09"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL Project",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) 🚙 🚚 🚐.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "danl200-hw5-Taratko-Christopher.html#word",
    "href": "danl200-hw5-Taratko-Christopher.html#word",
    "title": "danl200-hw5-Taratko-Christopher.qmd",
    "section": "Word",
    "text": "Word\n\n2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "quarto-template.html",
    "href": "quarto-template.html",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "",
    "text": "oj &lt;- read_csv('https://bcdanl.github.io/data/dominick_oj.csv')\nnvars &lt;- format(round(ncol(oj), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(oj), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 4; the number of observations is 28,947.\nRoses are red\nviolets are blue."
  },
  {
    "objectID": "quarto-template.html#data-summary",
    "href": "quarto-template.html#data-summary",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "quarto-template.html#data-visualization",
    "href": "quarto-template.html#data-visualization",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\noj %&gt;% \n  ggplot(aes(x = log(sales), \n             y = log(price),\n             color = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = lm, se = F) +\n  facet_wrap(.~ad) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "quarto-template.html#data-transformation",
    "href": "quarto-template.html#data-transformation",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.3 Data Transformation",
    "text": "2.3 Data Transformation\n\nob_sum1 &lt;- oj %&gt;% \n  group_by(brand, ad) %&gt;% \n  summarise(sales_tot = sum(sales, na.rm = T),\n            price_mean = round(mean(price, na.rm = T), 2))"
  },
  {
    "objectID": "quarto-template.html#analysis",
    "href": "quarto-template.html#analysis",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "quarto-template.html#quotes",
    "href": "quarto-template.html#quotes",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n“The truth is rarely pure and never simple.”\n— Oscar Wilde"
  },
  {
    "objectID": "quarto-template.html#inserting-figures",
    "href": "quarto-template.html#inserting-figures",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure 1.\n\n\n\n\n\nFigure 1: DANL Tiger"
  },
  {
    "objectID": "quarto-template.html#inserting-a-html-page",
    "href": "quarto-template.html#inserting-a-html-page",
    "title": "DANL 200: Christopher Taratko’s WorkspaceTeam Project",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "project.html#jack-katz---research-question-1-which-stocks-have-the-most-historical-volatility.",
    "href": "project.html#jack-katz---research-question-1-which-stocks-have-the-most-historical-volatility.",
    "title": "DANL Project",
    "section": "2.2 Jack Katz - Research Question 1: Which stocks have the most historical volatility.",
    "text": "2.2 Jack Katz - Research Question 1: Which stocks have the most historical volatility.\n\n2.2.1 Creating new variables for analysis, Separating by month day and year will make it easier to group and filter observations by year.\n#Historical volatility of each company for each year.  A simple measure of historical volatility is calculated by finding the standard deviation  of the close prices over a time series. In this case we found the standard deviation for  each stock for each year and then showed this data on ggplot.\n\nHistorical_Volatility &lt;- Volatility_analysis %&gt;% \n  group_by(Company, Year) %&gt;% \n  summarise(Volatility = sd(`Close/Last`))\n\nVolatility &lt;- ggplot(Historical_Volatility,\n       mapping = aes(x = as.numeric(Year),\n                     y = Volatility\n                     )) +\n  geom_point(color = \"blue\") +\n  geom_line(color = \"green\") +\n  facet_wrap( . ~Company) +\n  ggtitle(\"Stock Price Volatility from 2013-2023\", subtitle = \"In dollars\") +\n  labs(x = \"Year\") +\n  theme_economist_white()\n\nVolatility + scale_x_continuous(breaks = scales::breaks_width(2))"
  },
  {
    "objectID": "ctaratko.github.io-tmp/DANL200InClass.html",
    "href": "ctaratko.github.io-tmp/DANL200InClass.html",
    "title": "Danl200",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)\nlibrary(skimr)\n\nggplot(diamonds) +\n  geom_point(aes(x = carat, y = price, color = clarity)) +\n  scale_color_wsj()\n\nWarning: This manual palette can handle a maximum of 6 values. You have\nsupplied 8.\n\n\nWarning: Removed 5445 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot(diamonds) +\n  geom_bar(aes(x = clarity, fill = clarity)) +\n  scale_color_tableau()\n\n\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\ntable2 %&gt;%\n    pivot_wider(names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\ntable3 %&gt;% \n  separate(rate, into = c(\"cases\", \"population\"), sep = 2)\n\n# A tibble: 6 × 4\n  country      year cases population     \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n1 Afghanistan  1999 74    5/19987071     \n2 Afghanistan  2000 26    66/20595360    \n3 Brazil       1999 37    737/172006362  \n4 Brazil       2000 80    488/174504898  \n5 China        1999 21    2258/1272915272\n6 China        2000 21    3766/1280428583\n\ntable3 %&gt;% \n  separate(rate, into = c(\"cases\", \"population\"), sep = \"/\")\n\n# A tibble: 6 × 4\n  country      year cases  population\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntable5 %&gt;% \n  unite(new, century, year)\n\n# A tibble: 6 × 3\n  country     new   rate             \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 19_99 745/19987071     \n2 Afghanistan 20_00 2666/20595360    \n3 Brazil      19_99 37737/172006362  \n4 Brazil      20_00 80488/174504898  \n5 China       19_99 212258/1272915272\n6 China       20_00 213766/1280428583\n\ntable5 %&gt;% \n  unite(new, century, year, sep = \"\")\n\n# A tibble: 6 × 3\n  country     new   rate             \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            \n1 Afghanistan 1999  745/19987071     \n2 Afghanistan 2000  2666/20595360    \n3 Brazil      1999  37737/172006362  \n4 Brazil      2000  80488/174504898  \n5 China       1999  212258/1272915272\n6 China       2000  213766/1280428583\n\ndf1 &lt;- data.frame(id = 1:3, \n                  name = c(\"Alice\", \"Bob\", \"Charlie\")\n                  )\ndf2 &lt;- data.frame(id = 4:6, \n                  name = c(\"Dave\", \"Eve\", \"Frank\")\n                  )\ndf_rbind &lt;- rbind(df1, df2)\ndf_cbind &lt;- cbind(df1, df2) # better to rename id before cbind()\n\n\n#ggplot(health_cust) +\n#  geom_point(aes(x = age, y = income)) +\n#  scale_y_comma()\n\ngit clone https://ctaratko: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@github.com/ctaratko/ctaratko.github.io.git\n\nNVDA &lt;- read.csv(\"/Users/christophertaratko/Downloads/NVDA.csv\")"
  },
  {
    "objectID": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html",
    "href": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html#variable-description-for-starwars-data.frame",
    "href": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html#human-vs.-droid",
    "href": "ctaratko.github.io-tmp/danl-website-template-master/posts/Starwars2/starwars2.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "DANL35Ex2.html",
    "href": "DANL35Ex2.html",
    "title": "Project 2",
    "section": "",
    "text": "library(gapminder)\nlibrary(skimr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)\n\nggplot(gapminder) + \n  geom_point(aes(x = gdpPercap,y = year))\n\n\n\nlibrary(tidyverse)\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n# Spread across two tibbles\ntable4a  # cases\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\ntable4b\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583\n\n\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "PortfolioDevelopment.html",
    "href": "PortfolioDevelopment.html",
    "title": "Portfolio Development",
    "section": "",
    "text": "NVDY Reinvestment Data Planner\nThe Dividend Reinvestment Calculator is an array of charted values based on a given amount of NVDY in terms of USD Valuation or number of shares.  \nThe given valuation will be more or less volatile, as the provided date comes from the date of dividend payouts, rather than all daily valuations. This is not meant to be a secured planner, but just a general visualization of how money invested into this can grow and by what growth the stock has already seen\nContributions\nSite Owner: Christopher Taratko\nContributors: Professor Li Lu & Professor Byeong-Hak Choe\n\n\n\n\n\n\n\n\n\n\n\n\nFunctionality of The Reinvestment Calculator:\nThe Calculator / Graph is designed to be a User Input based service (Which will occur in the future) that will be able to calculate the monthly and overall returns.\n\nThe current calculator does not have an input function due to the lack of JavaScript knowledge on my end, but it will be temporarily resolved with a ShinyApp variable slider (Ex. '$50,$100,$500,$1000,$5000... $100000' or in terms of # of shares)."
  },
  {
    "objectID": "IndexTest.html",
    "href": "IndexTest.html",
    "title": "Christopher Taratko",
    "section": "",
    "text": "About Me\n\nI have majors in\nAccounting & Economics\n,with a Minor in\nData Analytics\nat SUNY Geneseo. When not working on college assignments, I enjoy sailing, snowboarding, zip-lining, rock climbing and gaming. Other interesting facts about me is that I have a Level 1 Sailing Certification, I race sailboats competitively through the summer and winter seasons, and my hopes for my college education is to bring a balance within Data Analytics and Accounting. I see both of these majors as essential to each other, especially now that AI will cause job uncertainty in programmable positions and is being developed to predict markets.\n\nEducation\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026 Minor in Data Analytics\nExperience\nDaidone Income Tax LLC - Mentorship\nLinkedIn Learning - Excel Tutorial\nLinkedIn Learning - Intermediate Excel\nLinkedIn Learning - Excel - Financial Functions in Depth\nLinkedIn Learning - Managing and Analyzing Data in Excel"
  },
  {
    "objectID": "IndexTest.html#education",
    "href": "IndexTest.html#education",
    "title": "Christopher Taratko",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026  Minor in Data Analytics"
  },
  {
    "objectID": "IndexTest.html#experience",
    "href": "IndexTest.html#experience",
    "title": "Christopher Taratko",
    "section": "Experience",
    "text": "Experience\nToo much for anyone to handle… (N/A) Testing to see if this is posted"
  },
  {
    "objectID": "IndexRenderDeploy.html",
    "href": "IndexRenderDeploy.html",
    "title": "Christopher Taratko",
    "section": "",
    "text": "About Me\n\nI have majors in\nAccounting & Economics\n,with a Minor in\nData Analytics\nat SUNY Geneseo. When not working on college assignments, I enjoy sailing, snowboarding, zip-lining, rock climbing and gaming. Other interesting facts about me is that I have a Level 1 Sailing Certification, I race sailboats competitively through the summer and winter seasons, and my hopes for my college education is to bring a balance within Data Analytics and Accounting. I see both of these majors as essential to each other, especially now that AI will cause job uncertainty in programmable positions and is being developed to predict markets.\n\nEducation\nState University of New York at Geneseo | Geneseo, NY  B.S in Accounting & Economics | Aug 2022 - May 2026 Minor in Data Analytics\nExperience\nDaidone Income Tax LLC - Mentorship\nLinkedIn Learning - Excel Tutorial\nLinkedIn Learning - Intermediate Excel\nLinkedIn Learning - Excel - Financial Functions in Depth\nLinkedIn Learning - Managing and Analyzing Data in Excel"
  },
  {
    "objectID": "Analytics200Review.html",
    "href": "Analytics200Review.html",
    "title": "Lab Exercises - DANL 200",
    "section": "",
    "text": "Data Analytics Lab Review (In Class Exercises)\nThese Lab Exercises consist of if statements, for loops, while loops, and repeat statements\n\n\n\n\n1 Lab 7 Work\n\n# IN-CLASS EXERCISE\n#   Create an if-else statement example in R that assigns a hypothetical starting salary based on different education levels. We’ll consider three levels of education: High School, Bachelor’s Degree, and Master’s Degree.\n\n#In this example:\n\n#   If the education level is “High School”, the starting salary is set to $30,000.\n#   If the education level is “Bachelor’s Degree”, the starting salary is set to $50,000.\n#   If the education level is “Master’s Degree”, the starting salary is set to $70,000.\n#   For any other education level not explicitly listed, the default starting salary is set to $40,000.\n\n# At the beginning, insert education level is “Bachelor’s Degree”, and Initialize the starting salary at 0. At the end use print() to show the result.\n\nEducation &lt;- \"Bachelor's Degree\"\nStarting_Salary &lt;- 0\nif (Education == \"High School\") {\n  Starting_Salary &lt;- 30000\n} else if (Education == \"Bachelor's Degree\") {\n  Starting_Salary &lt;- 50000\n} else if (Education == \"Master's Degree\") {\n  Starting_Salary &lt;- 70000\n} else {\n  Starting_Salary &lt;- 40000\n}\nprint(paste(\"This person has a \",Education,\" and their starting salary will be $\",Starting_Salary,sep = ''))\n\n[1] \"This person has a Bachelor's Degree and their starting salary will be $50000\"\n\n\n\n\n2 Lab 8\n\n#     In-Class Exercise: Adjusting Discount Rates Based on Purchase Amount\n# Exercise Description: Based on the previous example, now introduce an additional \n# condition: for premium members, if their purchase amount exceeds $200, they get \n# a 15% discount instead of 10%. all the rest are same, including non exceeds $200 \n# will get 10% and Non-premium members still do not receive any discount.\n\n\n# Purchase amounts and membership status\npurchase_amounts &lt;- c(100, 150, 200, 250, 300)\nis_premium_member &lt;- c(TRUE, FALSE, TRUE, FALSE, TRUE)\n\n# Initialize a vector to hold the final amounts, the initial value doesn't matter, eventually they will updated. But the length is important, it gives us the vector of results.\nfinal_amounts &lt;- numeric(length(purchase_amounts))\n\n# Use a for loop with if-else statement to apply discounts\nfor (i in 1:length(purchase_amounts)) {\n  if (is_premium_member[i] && purchase_amounts[i] &gt; 200) {\n    final_amounts[i] &lt;- purchase_amounts[i] * .85  # Applied 15% discount\n  } else if (is_premium_member[i]) {\n    final_amounts[i] &lt;- purchase_amounts[i] * 0.9  # Apply 10% discount\n  } else {\n    final_amounts[i] &lt;- purchase_amounts[i]  # No discount\n  } # My formatting (Works)\n}\n\n# for (i in 1:length(purchase_amounts)) \n#   if (is_premium_member[i]) {\n#     if (is_premium_member[i] && purchase_amounts[i] &gt; 200) {\n#       final_amounts[i] &lt;- purchase_amounts[i] * 0.85  # Applied 15% discount \n#     } else {\n#     final_amounts[i] &lt;- purchase_amounts[i] * 0.9  # Apply 10% discount\n#   }\n#     } else {\n#     final_amounts[i] &lt;- purchase_amounts[i]  # No discount\n#   } # Li Lu's Formatting (Cleaner Formatting, nested if statements)\n\nprint(final_amounts)\n\n[1]  90 150 180 250 255\n\n\n\n\n3 Lab 9\n\n# In-Class Exercise: Inventory for a popular book\n# Exercise Description: You own a small bookstore, and you keep track of the inventory for a popular book. Initially, you have 50 books in stock. Throughout the day, customers buy them, and you record each sale. Your policy is to order 30 more books whenever your stock drops below 10 to ensure you always have enough books to meet demand. The simulation stops after ordering more books once, for simplicity.\n\n\n# Initial Setup\nInitial_Stock &lt;- 50\nOrderThreshold &lt;- 10\nOrderQ &lt;- 30\nCurrentStock &lt;- Initial_Stock\nrepeat {\n  while (CurrentStock &gt; OrderThreshold) {\n  Q_Book_Sold &lt;- sample(1:5,1)\n  CurrentStock &lt;- CurrentStock - Q_Book_Sold\n  print(paste(\"The initial Stock of\",Initial_Stock,\"has been reduced to:\",CurrentStock))\n  } \n  if (CurrentStock &lt;= OrderThreshold) {\n  print(paste(\"Stock originally was at:\", CurrentStock))\n  CurrentStock &lt;- CurrentStock + OrderQ\n  print(paste(\"The updated Stock is now at:\", CurrentStock))\n  break\n  } \n}\n\n[1] \"The initial Stock of 50 has been reduced to: 48\"\n[1] \"The initial Stock of 50 has been reduced to: 44\"\n[1] \"The initial Stock of 50 has been reduced to: 42\"\n[1] \"The initial Stock of 50 has been reduced to: 41\"\n[1] \"The initial Stock of 50 has been reduced to: 40\"\n[1] \"The initial Stock of 50 has been reduced to: 38\"\n[1] \"The initial Stock of 50 has been reduced to: 35\"\n[1] \"The initial Stock of 50 has been reduced to: 31\"\n[1] \"The initial Stock of 50 has been reduced to: 28\"\n[1] \"The initial Stock of 50 has been reduced to: 23\"\n[1] \"The initial Stock of 50 has been reduced to: 18\"\n[1] \"The initial Stock of 50 has been reduced to: 15\"\n[1] \"The initial Stock of 50 has been reduced to: 12\"\n[1] \"The initial Stock of 50 has been reduced to: 11\"\n[1] \"The initial Stock of 50 has been reduced to: 6\"\n[1] \"Stock originally was at: 6\"\n[1] \"The updated Stock is now at: 36\"\n\n\n\n\n4 Another Class Exercise\n\nConsumerPoints &lt;- 85\nwhile (ConsumerPoints &lt; 140) {\n  if (ConsumerPoints &lt; 100) {\n    ConsumerPoints &lt;- ConsumerPoints + 5\n    print(ConsumerPoints)\n  } else if (ConsumerPoints &gt;= 100) {\n    ConsumerPoints &lt;- ConsumerPoints + 5\n    print(paste(\"You have\", ConsumerPoints, \"Points!\",\"\"))\n    readline(\"Would you like to Convert your Points to Cash: [Y/N] \")\n    break\n  }\n}\n\n[1] 90\n[1] 95\n[1] 100\n[1] \"You have 105 Points! \"\nWould you like to Convert your Points to Cash: [Y/N] \n\n\n\n\n[1] \"This Website has been fixed\""
  }
]